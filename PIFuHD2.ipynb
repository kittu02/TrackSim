{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYhlsDkg1Hwb"
      },
      "source": [
        "## Clone PIFuHD repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmpEwdOd1G1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22481dc7-98bd-4437-8863-9cc8f77d80bd"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/pifuhd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pifuhd'...\n",
            "remote: Enumerating objects: 222, done.\u001b[K\n",
            "remote: Counting objects: 100% (126/126), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 222 (delta 92), reused 82 (delta 82), pack-reused 96 (from 1)\u001b[K\n",
            "Receiving objects: 100% (222/222), 399.35 KiB | 2.12 MiB/s, done.\n",
            "Resolving deltas: 100% (114/114), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvQm-A8ESKb2"
      },
      "source": [
        "## Capture the image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######## A* #########"
      ],
      "metadata": {
        "id": "iXqFsWw49_XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvle9T10fB6g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35cead4b-a1dd-4b56-dec8-978efc7a0ee4"
      },
      "source": [
        "cd /content/pifuhd/sample_images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pifuhd/sample_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaV_7Yi8fM-B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f8b0eec8-4c68-47de-9b26-86d97406d3dc"
      },
      "source": [
        "######## A* #########\n",
        "# from google.colab import files\n",
        "# filename = list(files.upload().keys())[0]\n",
        "from IPython.display import Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def take_photo(filename='captured_image.png', quality=0.8):\n",
        "    js = f\"\"\"\n",
        "    async function takePhoto() {{\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'ðŸ“· Capture Photo';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      div.appendChild(video);\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({{ video: true }});\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "      stream.getTracks().forEach(track => track.stop());\n",
        "      div.remove();\n",
        "\n",
        "      return canvas.toDataURL('image/jpeg', {quality});\n",
        "    }}\n",
        "    takePhoto();\n",
        "    \"\"\"\n",
        "\n",
        "    data = eval_js(js)  # Only this runs the JS and gets the return\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return filename\n",
        "\n",
        "# Capture photo\n",
        "filename = take_photo()\n",
        "print(\"Image captured and saved as:\", filename)\n",
        "\n",
        "# Load into OpenCV\n",
        "image = cv2.imread(filename)\n",
        "if image is not None:\n",
        "    print(\"Image successfully loaded into OpenCV format. Shape:\", image.shape)\n",
        "else:\n",
        "    print(\"Failed to load image into OpenCV.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image captured and saved as: captured_image.png\n",
            "Image successfully loaded into OpenCV format. Shape: (480, 640, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edited the error"
      ],
      "metadata": {
        "id": "PC-hfOLa7oc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/pifuhd/apps/recon.py\"\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Edit line 150 (Python is 0-indexed, so line 150 is index 149)\n",
        "target_line = 149\n",
        "if target_line < len(lines):\n",
        "    lines[target_line] = \"        state_dict = torch.load(state_dict_path, map_location=cuda, weights_only=False)\\n\"\n",
        "\n",
        "# Write the modified lines back to the file\n",
        "with open(file_path, \"w\") as file:\n",
        "    file.writelines(lines)\n",
        "\n",
        "print(\"âœ… Line 150 updated successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AAdwjo04nuK",
        "outputId": "6aabe3a4-e490-4741-a3db-a568c8a11e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Line 150 updated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove background of person"
      ],
      "metadata": {
        "id": "3kujtV2073xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rembg\n",
        "!pip install onnxruntime\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0vT01EXFyDo",
        "outputId": "51440f63-cae4-41fc-9139-8b0bb42a106b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rembg\n",
            "  Downloading rembg-2.0.65-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from rembg) (4.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rembg) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from rembg) (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from rembg) (11.2.1)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.11/dist-packages (from rembg) (1.8.2)\n",
            "Collecting pymatting (from rembg)\n",
            "  Downloading PyMatting-1.1.13-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from rembg) (0.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from rembg) (1.15.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from rembg) (4.67.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (0.24.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch->rembg) (4.3.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pooch->rembg) (24.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch->rembg) (2.32.3)\n",
            "Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.11/dist-packages (from pymatting->rembg) (0.60.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (2025.3.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (0.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba!=0.49.0->pymatting->rembg) (0.43.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->rembg) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (2025.4.26)\n",
            "Downloading rembg-2.0.65-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m885.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMatting-1.1.13-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymatting, rembg\n",
            "Successfully installed pymatting-1.1.13 rembg-2.0.65\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.21.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rembg import remove\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "Q63CW6qi9OPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######## A* #########\n",
        "\n",
        "# Load the image with PIL\n",
        "input_image = Image.open(filename)\n",
        "\n",
        "# Remove background\n",
        "output_image = remove(input_image)\n",
        "\n",
        "# Save result\n",
        "output_filename = \"no_bg_\" + filename\n",
        "output_image.save(output_filename)\n",
        "\n",
        "print(\"Background removed. Saved as:\", output_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj170TuoEzKS",
        "outputId": "ee0e5c45-23f1-4533-b037-ac9900b946ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Background removed. Saved as: no_bg_captured_image.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbVmda9J5TDL"
      },
      "source": [
        "## Preprocess (for cropping image)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEzmmB01SOZp"
      },
      "source": [
        "######## A* #########\n",
        "\n",
        "import os\n",
        "try:\n",
        "  image_path = '/content/pifuhd/sample_images/%s' % output_filename\n",
        "except:\n",
        "  image_path = '/content/pifuhd/sample_images/test.png' # example image\n",
        "image_dir = os.path.dirname(image_path)\n",
        "file_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "# output pathes\n",
        "obj_path = '/content/pifuhd/results/pifuhd_final/recon/result_%s_256.obj' % file_name\n",
        "out_img_path = '/content/pifuhd/results/pifuhd_final/recon/result_%s_256.png' % file_name\n",
        "video_path = '/content/pifuhd/results/pifuhd_final/recon/result_%s_256.mp4' % file_name\n",
        "video_display_path = '/content/pifuhd/results/pifuhd_final/result_%s_256_display.mp4' % file_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krdnWwKGGh9Q",
        "outputId": "3cf1f780-a919-416d-efc1-e1e2442931f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pifuhd/sample_images/no_bg_captured_image.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "896EC7iQfXkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62fc5538-d8ca-4520-d253-d2b9177ba292"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pose Estimation setup"
      ],
      "metadata": {
        "id": "X_SFEIre8Mcp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtMjWGNU5STe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c6a7e3-bf1b-4718-d6e4-9b06d5448905"
      },
      "source": [
        "!git clone https://github.com/Daniil-Osokin/lightweight-human-pose-estimation.pytorch.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lightweight-human-pose-estimation.pytorch'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 124 (delta 21), reused 19 (delta 18), pack-reused 90 (from 1)\u001b[K\n",
            "Receiving objects: 100% (124/124), 230.29 KiB | 7.68 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######## A* #########"
      ],
      "metadata": {
        "id": "UXN4fsU2QsgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-vYklhI5dab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "138a6449-b6c3-4a35-eebe-3b41566d6097"
      },
      "source": [
        "cd /content/lightweight-human-pose-estimation.pytorch/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lightweight-human-pose-estimation.pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRod9SOu77I6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d0af2bd-087b-45ee-d1c0-825c88863ddf"
      },
      "source": [
        "!wget https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estimation/checkpoint_iter_370000.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-09 08:48:45--  https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estimation/checkpoint_iter_370000.pth\n",
            "Resolving download.01.org (download.01.org)... 92.122.14.20, 2600:1409:9800:168c::a87, 2600:1409:9800:1689::a87\n",
            "Connecting to download.01.org (download.01.org)|92.122.14.20|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87959810 (84M) [application/octet-stream]\n",
            "Saving to: â€˜checkpoint_iter_370000.pthâ€™\n",
            "\n",
            "checkpoint_iter_370 100%[===================>]  83.88M   233MB/s    in 0.4s    \n",
            "\n",
            "2025-05-09 08:48:46 (233 MB/s) - â€˜checkpoint_iter_370000.pthâ€™ saved [87959810/87959810]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdRcDXe38lHB"
      },
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from models.with_mobilenet import PoseEstimationWithMobileNet\n",
        "from modules.keypoints import extract_keypoints, group_keypoints\n",
        "from modules.load_state import load_state\n",
        "from modules.pose import Pose, track_poses\n",
        "import demo\n",
        "\n",
        "def get_rect(net, images, height_size):\n",
        "    net = net.eval()\n",
        "\n",
        "    stride = 8\n",
        "    upsample_ratio = 4\n",
        "    num_keypoints = Pose.num_kpts\n",
        "    previous_poses = []\n",
        "    delay = 33\n",
        "    for image in images:\n",
        "        rect_path = image.replace('.%s' % (image.split('.')[-1]), '_rect.txt')\n",
        "        img = cv2.imread(image, cv2.IMREAD_COLOR)\n",
        "        orig_img = img.copy()\n",
        "        orig_img = img.copy()\n",
        "        heatmaps, pafs, scale, pad = demo.infer_fast(net, img, height_size, stride, upsample_ratio, cpu=False)\n",
        "\n",
        "        total_keypoints_num = 0\n",
        "        all_keypoints_by_type = []\n",
        "        for kpt_idx in range(num_keypoints):  # 19th for bg\n",
        "            total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n",
        "\n",
        "        pose_entries, all_keypoints = group_keypoints(all_keypoints_by_type, pafs)\n",
        "        for kpt_id in range(all_keypoints.shape[0]):\n",
        "            all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio - pad[1]) / scale\n",
        "            all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio - pad[0]) / scale\n",
        "        current_poses = []\n",
        "\n",
        "        rects = []\n",
        "        for n in range(len(pose_entries)):\n",
        "            if len(pose_entries[n]) == 0:\n",
        "                continue\n",
        "            pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1\n",
        "            valid_keypoints = []\n",
        "            for kpt_id in range(num_keypoints):\n",
        "                if pose_entries[n][kpt_id] != -1.0:  # keypoint was found\n",
        "                    pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n",
        "                    pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n",
        "                    valid_keypoints.append([pose_keypoints[kpt_id, 0], pose_keypoints[kpt_id, 1]])\n",
        "            valid_keypoints = np.array(valid_keypoints)\n",
        "\n",
        "            if pose_entries[n][10] != -1.0 or pose_entries[n][13] != -1.0:\n",
        "              pmin = valid_keypoints.min(0)\n",
        "              pmax = valid_keypoints.max(0)\n",
        "\n",
        "              center = (0.5 * (pmax[:2] + pmin[:2])).astype(np.int_)\n",
        "              radius = int(0.65 * max(pmax[0]-pmin[0], pmax[1]-pmin[1]))\n",
        "            elif pose_entries[n][10] == -1.0 and pose_entries[n][13] == -1.0 and pose_entries[n][8] != -1.0 and pose_entries[n][11] != -1.0:\n",
        "              # if leg is missing, use pelvis to get cropping\n",
        "              center = (0.5 * (pose_keypoints[8] + pose_keypoints[11])).astype(np.int_)\n",
        "              radius = int(1.45*np.sqrt(((center[None,:] - valid_keypoints)**2).sum(1)).max(0))\n",
        "              center[1] += int(0.05*radius)\n",
        "            else:\n",
        "              center = np.array([img.shape[1]//2,img.shape[0]//2])\n",
        "              radius = max(img.shape[1]//2,img.shape[0]//2)\n",
        "\n",
        "            x1 = center[0] - radius\n",
        "            y1 = center[1] - radius\n",
        "\n",
        "            rects.append([x1, y1, 2*radius, 2*radius])\n",
        "\n",
        "        np.savetxt(rect_path, np.array(rects), fmt='%d')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6cGZD6f6IaY"
      },
      "source": [
        "######## A* #########\n",
        "\n",
        "net = PoseEstimationWithMobileNet()\n",
        "checkpoint = torch.load('checkpoint_iter_370000.pth', map_location='cpu')\n",
        "load_state(net, checkpoint)\n",
        "\n",
        "get_rect(net.cuda(), [image_path], 512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0rgMInwTt0s"
      },
      "source": [
        "## Download the Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######## A* #########"
      ],
      "metadata": {
        "id": "SZZew0f--j1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrIcZweSNRFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2cc0159-5097-4bb0-fa6c-f71cde693ca7"
      },
      "source": [
        "cd /content/pifuhd/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pifuhd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3jjm6HuQRk8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5dca26f-3b67-4e46-eae6-5a2e2cbf1b1c"
      },
      "source": [
        "!sh ./scripts/download_trained_model.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ mkdir -p checkpoints\n",
            "+ cd checkpoints\n",
            "+ wget https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt pifuhd.pt\n",
            "--2025-05-09 08:48:58--  https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.51, 3.163.189.14, 3.163.189.108, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.51|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1548375177 (1.4G) [application/octet-stream]\n",
            "Saving to: â€˜pifuhd.ptâ€™\n",
            "\n",
            "pifuhd.pt           100%[===================>]   1.44G   100MB/s    in 9.2s    \n",
            "\n",
            "2025-05-09 08:49:08 (161 MB/s) - â€˜pifuhd.ptâ€™ saved [1548375177/1548375177]\n",
            "\n",
            "--2025-05-09 08:49:08--  http://pifuhd.pt/\n",
            "Resolving pifuhd.pt (pifuhd.pt)... failed: Name or service not known.\n",
            "wget: unable to resolve host address â€˜pifuhd.ptâ€™\n",
            "FINISHED --2025-05-09 08:49:08--\n",
            "Total wall clock time: 9.5s\n",
            "Downloaded: 1 files, 1.4G in 9.2s (161 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6heKcA-0QEBw"
      },
      "source": [
        "## Run PIFuHD\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5995t2PnQTmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae08b87e-d256-4ad6-c10f-74642e45878f"
      },
      "source": [
        "######## A* #########\n",
        "\n",
        "# Warning: all images with the corresponding rectangle files under -i will be processed.\n",
        "!python -m apps.simple_test -r 256 --use_rect -i $image_dir\n",
        "\n",
        "# seems that 256 is the maximum resolution that can fit into Google Colab.\n",
        "# If you want to reconstruct a higher-resolution mesh, please try with your own machine."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resuming from  ./checkpoints/pifuhd.pt\n",
            "Warning: opt is overwritten.\n",
            "test data size:  1\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "generate mesh (test) ...\n",
            "  0% 0/1 [00:00<?, ?it/s]./results/pifuhd_final/recon/result_no_bg_captured_image_256.obj\n",
            "[ WARN:0@12.141] global loadsave.cpp:848 imwrite_ Unsupported depth image for selected encoder is fallbacked to CV_8U.\n",
            "100% 1/1 [00:05<00:00,  5.77s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To run again run cells containing\n",
        "`######## A* #########`\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kRwcEysNzreE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qmlY8b9LOT9Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}